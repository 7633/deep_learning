#Useful links

How to use
----
Here is a collection of useful resources to learn / understand / discover more about (Deep) Learning. It will be updated regularly, I'll be glad if you have  [suggestions](https://github.com/Vict0rSch/Deep-Learning/pulls) to this list. 

Resources can be either research papers, explanatory website or even a well-written Wikipedia page. Topics are wide, I hope you'll find what you need. 

Starting with (Deep) Learning
----

1. **<http://www.r2d3.us/>** A **beginner's** introduction to **machine learning** (with decision trees), how it works and what is at stake. The website is amazingly beautiful and didactical. If you're ehre, on *this* page, you probably won't need to read through that. But still, it's too good to miss. And worth sharing with everyone.
	
2. **<https://www.coursera.org/learn/machine-learning>** Here is [Andrew Ng](http://www.andrewng.org/)'s most famous MOOC on Coursera. Again, this is a "*start-from-scratch*" ressource, it needs little maths and is easy going with coding.  The point here is to teach about **machine learnin**g in general, amongst which stand neural networks. It uses [Octave](https://www.gnu.org/software/octave/) (free version of Matlab) which is a downside for me *vs* Python but this is not important if you're just starting and if you're not you can always do it in Python anyway. 

3. **<http://neuralnetworksanddeeplearning.com/>** This is a **_goldmine_** to start with Deep Learning and understand neural networks. It starts from scratch, and takes you through the **backpropagation** algorithm, **regularization**, tips to train your networks etc. up to explaining **convolutional** networks and introducing recurrent ones. It needs very little maths and uses a simple Python code to wallk you through the **implementation** of feedforward and convolutional neural nets.

	_This is where I started with Deep Learning and I want to **thank [M. Nielsen](http://michaelnielsen.org/)** for his very informative and pedagogical work._
	
Reading papers
---
If you like reading papers and read a lot of papers (or at least once a month) I suggest you download and use **[Mendeley](https://www.mendeley.com/dashboard/)**:
> Free reference manager and PDF organizer

The point is that you will be able to store and organize the papers you read to find them later on without having to dig in the web. Moreover it is super-useful to generate Latex bibliographies.

I do not know if it is the best tool you can find, it's just that I use it and like it.
	

General Deep Learning papers and books
---

1. **[Deep Learning review](http://www.nature.com/articles/nature14539.epdf?referrer_access_token=K4awZz78b5Yn2_AoPV_4Y9RgN0jAjWel9jnR3ZoTv0PU8PImtLRceRBJ32CtadUBVOwHuxbf2QgphMCsA6eTOw64kccq9ihWSKdxZpGPn2fn3B_8bxaYh0svGFqgRLgaiyW6CBFAb3Fpm6GbL8a_TtQQDWKuhD1XKh_wxLReRpGbR_NdccoaiKP5xvzbV-x7b_7Y64ZSpqG6kmfwS6Q1rw%3D%3D&tracking_referrer=www.nature.com)** in *Nature* (2015) by Y. LeCun, Y. Bengio and G. Hinton

	>Deep learning allows computational models that are composed of multiple processing layers to learn representations of data with multiple levels of abstraction. These methods have dramatically improved the state-of-the-art in speech recognition, visual object recognition, object detection and many other domains such as drug discovery and genomics. Deep learning discovers intricate structure in large data sets by using the backpropagation algorithm to indicate how a machine should change its internal parameters that are used to compute the representation in each layer from the representation in the previous layer. Deep convolutional nets have brought about breakthroughs in processing images, video, speech and audio, whereas recurrent nets have shone light on sequential data such as text and speech.


2. **[Deep Learning Book (Draft)](http://www.deeplearningbook.org/)**	by I. Goodfellow, Y. Bengio and A. Courville. The book is not finished and the html version is quite ugly but it still is exhaustive and precise.

3. **[Pattern Recognition and Machine Learning](http://www.rmki.kfki.hu/~banmi/elte/Bishop%20-%20Pattern%20Recognition%20and%20Machine%20Learning.pdf)** by C. Bishop (2006). This 700 pages **book** is one of the Bibles of **machine learning**, tackling major subjects such as Graphical Models, Kernel Methods, Linear Models and ... Neural Networks. It is quite maths-oriented but very precise and useful. 

4. **[Practical Recommendations for Gradient-Based Training of Deep
Architectures](http://arxiv.org/pdf/1206.5533v2.pdf)** by Y. Bengio (2012).

	>Learning algorithms related to artificial neural networks
and in particular for Deep Learning may seem
to involve many bells and whistles, called hyperparameters.
This chapter is meant as a practical
guide with recommendations for some of the most
commonly used hyper-parameters, in particular in
the context of learning algorithms based on backpropagated
gradient and gradient-based optimization.
It also discusses how to deal with the fact that
more interesting results can be obtained when allowing
one to adjust many hyper-parameters. Overall, it
describes elements of the practice used to successfully
and efficiently train and debug large-scale and often
deep multi-layer neural networks. It closes with open
questions about the training difficulties observed with
deeper architectures.


Other reading lists
---
The following are insanely good, exhaustive and pertinent reading/resources lists. I suggest you browse them because my point here is not to compete with them.

1. **<https://github.com/ujjwalkarn/Machine-Learning-Tutorials>** A general list on a **lot** of **machine learning** fields. 

2. **<https://github.com/ChristosChristofidis/awesome-deep-learning>** **Deep Learning**-focused list of resources, going from researches to datasets and frameworks. 

3. **<http://deeplearning.net/reading-list/>** Research and Deep Learing-oriented reading list.
